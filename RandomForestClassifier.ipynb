{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0967d707-d202-480f-93f6-680f63d5414f",
   "metadata": {},
   "source": [
    "## Minimal Random Forest Classifier Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d04d0e4-e77e-4d7b-ba81-6242c6241c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9657690c-5d72-4cd1-a1c5-b63788e97e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77f6396-81e7-4a57-91ba-c0ef2ef75389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e1ecf89-ceaa-416c-9488-e82b80936e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(\n",
    "        self, *, feature=None, threshold=None, left=None, right=None, value=None\n",
    "    ):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "    @property\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3cb7725-6cd2-49c2-97b2-156f2d2511cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier(BaseEstimator):\n",
    "    def __init__(self, max_depth=100, min_samples_split=2, n_features=None):\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features = n_features\n",
    "        self.root = None\n",
    "        self.X_features_n = None\n",
    "\n",
    "    @staticmethod\n",
    "    def _most_frequent(x):  # Finding most frequent number of an array.\n",
    "        return mode(x, keepdims=False)[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def _entropy(x):\n",
    "        return -np.sum(\n",
    "            np.fromiter(\n",
    "                (\n",
    "                    p * np.log(p)\n",
    "                    for p in np.divide(np.bincount(x), (x.shape[0]))\n",
    "                    if p > 0\n",
    "                ),\n",
    "                dtype=np.float64,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _split(x, threshold):\n",
    "        condition = x <= threshold\n",
    "        return (\n",
    "            np.argwhere(condition).flatten(),\n",
    "            np.argwhere(np.invert(condition)).flatten(),\n",
    "        )\n",
    "\n",
    "    def _information_gain(self, x, y, threshold):\n",
    "        parent_entropy = self._entropy(y)\n",
    "        # child\n",
    "        left_idx, right_idx = self._split(x, threshold)\n",
    "        if (left_idx.size == 0) or (right_idx.size == 0):\n",
    "            return 0\n",
    "\n",
    "        # Weighted average of children entropy\n",
    "        child_left_entropy = self._entropy(y[left_idx])\n",
    "        child_right_entropy = self._entropy(y[right_idx])\n",
    "        child_entropy = (\n",
    "            left_idx.shape[0] * child_left_entropy\n",
    "            + right_idx.shape[0] * child_right_entropy\n",
    "        ) / y.shape[0]\n",
    "\n",
    "        return parent_entropy - child_entropy\n",
    "\n",
    "    def _best_split(self, X, y, features_idx):\n",
    "        best_gain = 0\n",
    "        split_idx, split_threshold = None, None\n",
    "\n",
    "        for feature_idx in features_idx:\n",
    "            thresholds = np.unique(X[:, feature_idx])\n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(X[:, feature_idx], y, threshold)\n",
    "\n",
    "                if gain >= best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feature_idx\n",
    "                    split_threshold = threshold\n",
    "\n",
    "        return split_idx, split_threshold\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_labels = np.unique(y).shape[0]\n",
    "\n",
    "        # In these cases, we need to stop\n",
    "        if (\n",
    "            depth >= self.max_depth\n",
    "            or n_labels == 1\n",
    "            or X.shape[0] < self.min_samples_split\n",
    "        ):\n",
    "            return Node(value=self._most_frequent(y))\n",
    "\n",
    "        best_feature_idx, best_threshold = self._best_split(\n",
    "            X, y, np.random.choice(X.shape[1], self.n_features, replace=False)\n",
    "        )\n",
    "        # Create child\n",
    "        left_idx, right_idx = self._split(X[:, best_feature_idx], best_threshold)\n",
    "        left_child = self._grow_tree(X[left_idx, :], y[left_idx], depth=depth + 1)\n",
    "        right_child = self._grow_tree(X[right_idx, :], y[right_idx], depth=depth + 1)\n",
    "\n",
    "        return Node(\n",
    "            feature=best_feature_idx,\n",
    "            threshold=best_threshold,\n",
    "            left=left_child,\n",
    "            right=right_child,\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        assert X.shape[0] == y.shape[0]\n",
    "        self.X_features_n = X.shape[1]\n",
    "\n",
    "        self.n_features = X.shape[1] if self.n_features is None else self.n_features\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _predict_one(self, x):\n",
    "        node = self.root\n",
    "        while not node.is_leaf_node:\n",
    "            if x[node.feature] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "\n",
    "        return node.value\n",
    "\n",
    "    def predict(self, X):\n",
    "        assert X.shape[1] == self.X_features_n, f\"{X.shape[1]=} != {self.X_features_n=}\"\n",
    "        return np.array([self._predict_one(x) for x in X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daa6b68a-37c7-4e6f-8d04-e519d0d31ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForsetClassifier(BaseEstimator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators=25,\n",
    "        max_depth=20,\n",
    "        min_samples_split=2,\n",
    "        n_features=None,\n",
    "        undersampling=1,\n",
    "        n_jobs=-1,\n",
    "    ):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_features = n_features\n",
    "        self.undersampling = undersampling\n",
    "        self.trees = [\n",
    "            DecisionTreeClassifier(\n",
    "                min_samples_split=min_samples_split,\n",
    "                max_depth=max_depth,\n",
    "                n_features=n_features,\n",
    "            )\n",
    "            for _ in range(n_estimators)\n",
    "        ]\n",
    "        self.masks = None\n",
    "        self.X_features_n = None\n",
    "        self.n_jobs = None if n_jobs == -1 else n_jobs\n",
    "\n",
    "    def _bagging(self, n):\n",
    "        return np.random.choice(n, int(self.undersampling * n), replace=True)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        assert X.shape[0] == y.shape[0]\n",
    "        self.X_features_n = X.shape[1]\n",
    "\n",
    "        with ProcessPoolExecutor(max_workers=self.n_jobs) as executor:\n",
    "            tasks = [\n",
    "                executor.submit(tree.fit, X[mask, :], y[mask])\n",
    "                for tree, mask in zip(\n",
    "                    self.trees,\n",
    "                    (self._bagging(X.shape[0]) for _ in range(self.n_estimators)),\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            trained_trees = []\n",
    "            for task in as_completed(tasks):\n",
    "                trained_trees.append(task.result())\n",
    "\n",
    "            self.trees = trained_trees\n",
    "\n",
    "    def predict(self, X):\n",
    "        assert X.shape[1] == self.X_features_n\n",
    "        predictions = []\n",
    "\n",
    "        with ProcessPoolExecutor(max_workers=self.n_jobs) as executor:\n",
    "            tasks = [executor.submit(tree.predict, X) for tree in self.trees]\n",
    "            for task in as_completed(tasks):\n",
    "                predictions.append(task.result())\n",
    "\n",
    "        return np.apply_along_axis(\n",
    "            lambda col: mode(col, keepdims=False)[0], 0, np.vstack(predictions)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d8fcb9-cf82-46c5-bc81-495c51e7d99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=2_000, n_features=10, n_classes=3, n_informative=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf6a9eb3-e490-4d23-841e-e6d3f6543181",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForsetClassifier(n_estimators=20, max_depth=10, undersampling=0.6, n_jobs=-1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "342b37da-6c32-49dc-90cf-13a5dbeddf74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9665"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, clf.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54dfc169-c355-443e-ae7c-dbd994b1bf78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8550196171722431"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import hmean\n",
    "hmean(cross_val_score(RandomForsetClassifier(n_estimators=25, max_depth=10, undersampling=0.6), X, y, scoring='accuracy', cv=10, n_jobs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "536417c8-3c2c-49f6-b0a1-13e7f6ce1314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8657871057622333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as sk_clf\n",
    "hmean(cross_val_score(sk_clf(max_depth=10), X, y, scoring='accuracy', cv=10, n_jobs=-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
